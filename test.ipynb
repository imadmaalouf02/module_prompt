{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test_PromptGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\anaconda3\\envs\\project\\lib\\site-packages\\torch\\_subclasses\\functional_tensor.py:295: UserWarning: Failed to initialize NumPy: \n",
      "\n",
      "IMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO SOLVE THIS ISSUE!\n",
      "\n",
      "Importing the numpy C-extensions failed. This error can happen for\n",
      "many reasons, often due to issues with your setup or how NumPy was\n",
      "installed.\n",
      "\n",
      "We have compiled some common reasons and troubleshooting tips at:\n",
      "\n",
      "    https://numpy.org/devdocs/user/troubleshooting-importerror.html\n",
      "\n",
      "Please note and check the following:\n",
      "\n",
      "  * The Python version is: Python3.9 from \"c:\\Users\\HP\\anaconda3\\envs\\project\\python.exe\"\n",
      "  * The NumPy version is: \"1.23.5\"\n",
      "\n",
      "and make sure that they are the versions you expect.\n",
      "Please carefully study the documentation linked above for further help.\n",
      "\n",
      "Original error was: DLL load failed while importing _multiarray_umath: Le module spécifié est introuvable.\n",
      " (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\tensor_numpy.cpp:84.)\n",
      "  cpu = _conversion_method_template(device=torch.device(\"cpu\"))\n"
     ]
    }
   ],
   "source": [
    "from transformers import VisionEncoderDecoderModel, ViTImageProcessor, AutoTokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Analyser_Components.PromptGenerator import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Config of the encoder: <class 'transformers.models.vit.modeling_vit.ViTModel'> is overwritten by shared encoder config: ViTConfig {\n",
      "  \"architectures\": [\n",
      "    \"ViTModel\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.0,\n",
      "  \"encoder_stride\": 16,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.0,\n",
      "  \"hidden_size\": 768,\n",
      "  \"image_size\": 224,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"model_type\": \"vit\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_channels\": 3,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"patch_size\": 16,\n",
      "  \"qkv_bias\": true,\n",
      "  \"transformers_version\": \"4.46.1\"\n",
      "}\n",
      "\n",
      "Config of the decoder: <class 'transformers.models.gpt2.modeling_gpt2.GPT2LMHeadModel'> is overwritten by shared decoder config: GPT2Config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"add_cross_attention\": true,\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"decoder_start_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"is_decoder\": true,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"pad_token_id\": 50256,\n",
      "  \"reorder_and_upcast_attn\": false,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_by_inverse_layer_idx\": false,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.46.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt_generator = PromptGenerator(image_directory=\"./data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n",
      "You may ignore this warning if your `pad_token_id` (50256) is identical to the `bos_token_id` (50256), `eos_token_id` (50256), or the `sep_token_id` (None), and your input is not padded.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 20 prompts for image1.jpg\n",
      "Generated 20 prompts for image2.jpg\n",
      "Generated 20 prompts for image3.jpg\n"
     ]
    }
   ],
   "source": [
    "generated_prompts = prompt_generator.generate_prompts(max_length=15, num_prompts=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompts for image1.jpg:\n",
      "- a person is playing a guitar in front of a keyboard\n",
      "- a piano player is playing music on a piano\n",
      "- a piano playing piano while other musicians listen\n",
      "- a piano on a piano playing instrument on a crowded concert stage\n",
      "- a person playing piano on a bass with strings next to it\n",
      "- the guitar player uses a keyboard and a piano\n",
      "- a man in glasses playing a piano in front of the keyboard of a\n",
      "- a person playing a keyboard in front of a big piano\n",
      "- a keyboard and instruments are hanging in a small room\n",
      "- a piano player looking at the track on the piano\n",
      "- a hand reaches out to touch a guitar\n",
      "- a guitar playing in the middle of piano music\n",
      "- a piano and guitar player in front of the piano\n",
      "- a man is playing a piano on a piano bench\n",
      "- a person playing some keyboard on a piano\n",
      "- a piano player playing a musical instrument\n",
      "- a band playing keyboard in a black and white orchestra\n",
      "- a guitar string is playing in front of a piano\n",
      "- a vintage piano in a crowded piano room being played\n",
      "- a guitar player playing and playing on a piano keyboard\n",
      "Prompts for image2.jpg:\n",
      "- a man holding a guitar near a rock wall\n",
      "- man in blue shirt and tie playing a piano\n",
      "- a man in a black shirt and a white guitar\n",
      "- a man is playing instruments and posing for the camera\n",
      "- a man in a suit and tie playing music before a drum\n",
      "- a guitarist playing a guitar in a bright blue colored area\n",
      "- a man singing a melody on a guitar\n",
      "- a man standing in front of a musical instrument\n",
      "- the musician is holding a trumpet while on stage\n",
      "- a man in grey shirt playing guitar standing in front of a white boat\n",
      "- a man in a suit playing a guitar\n",
      "- a man in a black shirt and blue pants playing a piano\n",
      "- a man wearing a blue shirt and black hat on a guitar playing a\n",
      "- a man in a red hat and bow tie playing a musical instrument\n",
      "- a man in grey shirt standing by a piano\n",
      "- a man stands next to a guitar in front of water\n",
      "- a man playing guitar during a recording session\n",
      "- a man in black suit is playing a guitar\n",
      "- a man sitting in front of a piano playing a song\n",
      "- a male musician in musical attire playing a string guitar\n",
      "Prompts for image3.jpg:\n",
      "- a young man with a beard smoking a cigarette and a hat on\n",
      "- a man in a blue shirt a black tie and black shoes\n",
      "- a man wearing sunglasses and a green hat holding his mike\n",
      "- a man holding a video game controller\n",
      "- a man wearing a blue helmet, sunglasses, and a hat\n",
      "- man in hat and sunglasses holding a green smartphone\n",
      "- the bearded man in black sunglasses is looking at his cell phone\n",
      "- a man wearing sunglasses looking out his cell phone\n",
      "- a man in black sweater wears a hat while holding a cell phone\n",
      "- a man that is holding a cell phone up\n",
      "- man wearing a green hat while holding up several cellphones\n",
      "- a man with glasses and a hat holding a cell phone\n",
      "- a man in a hat using a cell phone\n",
      "- a man wearing glasses and a hat is holding a phone\n",
      "- a man with sunglasses wearing a black hat and glasses\n",
      "- a person in a a cap is holding a cell phone\n",
      "- a man in a dark suit sitting down looking at his cell phone\n",
      "- a man sitting in a blue suit with a green, green and blue\n",
      "- a person dressed as a cat with a bag\n",
      "- a hipster with a t-shirt, vest and a hat is\n"
     ]
    }
   ],
   "source": [
    "for image_name, prompts in generated_prompts.items():\n",
    "        print(f\"Prompts for {image_name}:\")\n",
    "        for prompt in prompts:\n",
    "            print(f\"- {prompt}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test_prompt_analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package cmudict to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package cmudict is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Importer la classe depuis le fichier .py\n",
    "from Analyser_Components.prompt_analyz import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemple de dictionnaire de prompts à analyser\n",
    "prompts_dict = {\n",
    "    'image1.jpg': [\n",
    "        \"A beautiful sunset over the mountains.\",\n",
    "        \"A group of people hiking in the hills.\",\n",
    "        \"An aerial view of the city skyline during sunset.\"\n",
    "    ],\n",
    "    'image2.jpg': [\n",
    "        \"A cat sitting on a windowsill.\",\n",
    "        \"A dog playing in the park.\",\n",
    "        \"A person reading a book in a garden.\"\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Créer une instance de prompt_analyzer\n",
    "analyzer = prompt_analyzer(prompts_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyser les prompts (choisir d'activer la complexité ou la lisibilité)\n",
    "analyzer.process_prompts(readability=True, complexity=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   image_name                            best_prompt1  \\\n",
      "0  image1.jpg  A beautiful sunset over the mountains.   \n",
      "1  image2.jpg          A cat sitting on a windowsill.   \n",
      "\n",
      "                             best_prompt2  \\\n",
      "0  A group of people hiking in the hills.   \n",
      "1              A dog playing in the park.   \n",
      "\n",
      "                                        best_prompt3  \n",
      "0  An aerial view of the city skyline during sunset.  \n",
      "1               A person reading a book in a garden.  \n"
     ]
    }
   ],
   "source": [
    "# Vérifier le contenu du fichier CSV généré\n",
    "import pandas as pd\n",
    "\n",
    "# Charger le fichier CSV et afficher son contenu\n",
    "results_df = pd.read_csv('prompt_results.csv')\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   image_name                            best_prompt1  \\\n",
      "0  image1.jpg  A beautiful sunset over the mountains.   \n",
      "1  image2.jpg          A cat sitting on a windowsill.   \n",
      "\n",
      "                             best_prompt2  \\\n",
      "0  A group of people hiking in the hills.   \n",
      "1              A dog playing in the park.   \n",
      "\n",
      "                                        best_prompt3  \n",
      "0  An aerial view of the city skyline during sunset.  \n",
      "1               A person reading a book in a garden.  \n"
     ]
    }
   ],
   "source": [
    "# Vérifier le contenu du fichier CSV généré\n",
    "import pandas as pd\n",
    "\n",
    "# Charger le fichier CSV et afficher son contenu\n",
    "results_df = pd.read_csv('prompt_results.csv')\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test_module_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\anaconda3\\envs\\project\\lib\\site-packages\\torch\\_subclasses\\functional_tensor.py:295: UserWarning: Failed to initialize NumPy: \n",
      "\n",
      "IMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO SOLVE THIS ISSUE!\n",
      "\n",
      "Importing the numpy C-extensions failed. This error can happen for\n",
      "many reasons, often due to issues with your setup or how NumPy was\n",
      "installed.\n",
      "\n",
      "We have compiled some common reasons and troubleshooting tips at:\n",
      "\n",
      "    https://numpy.org/devdocs/user/troubleshooting-importerror.html\n",
      "\n",
      "Please note and check the following:\n",
      "\n",
      "  * The Python version is: Python3.9 from \"c:\\Users\\HP\\anaconda3\\envs\\project\\python.exe\"\n",
      "  * The NumPy version is: \"1.23.5\"\n",
      "\n",
      "and make sure that they are the versions you expect.\n",
      "Please carefully study the documentation linked above for further help.\n",
      "\n",
      "Original error was: DLL load failed while importing _multiarray_umath: Le module spécifié est introuvable.\n",
      " (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\tensor_numpy.cpp:84.)\n",
      "  cpu = _conversion_method_template(device=torch.device(\"cpu\"))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from Analyser_Components.object_detector import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts_dict = {\n",
    "    'image1.jpg': [\n",
    "        \"A dog running in the park.\",\n",
    "        \"A cat sitting on a windowsill.\",\n",
    "        \"A person reading a book in the garden.\"\n",
    "    ],\n",
    "    'image2.jpg': [\n",
    "        \"A person playing soccer.\",\n",
    "        \"A dog and a cat sitting together.\",\n",
    "        \"A bird flying in the sky.\"\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at facebook/detr-resnet-50 were not used when initializing DetrForObjectDetection: ['model.backbone.conv_encoder.model.layer1.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer2.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer3.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer4.0.downsample.1.num_batches_tracked']\n",
      "- This IS expected if you are initializing DetrForObjectDetection from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DetrForObjectDetection from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "detector = ObjectDetector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'image1.jpg': ['dog', 'cat', 'person'], 'image2.jpg': ['person', 'dog, cat', '']}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Extract classes (object labels) from the prompts\n",
    "extracted_classes = detector.extract_classes_from_prompts(prompts_dict)\n",
    "\n",
    "# Output the extracted class labels for each prompt\n",
    "print(extracted_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
